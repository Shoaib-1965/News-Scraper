# **ğŸ“° Google News Scraper**

## **ğŸ” Automated News Article Extraction Tool**

**Google News Scraper** is a powerful Python-based web scraping tool that automatically extracts and analyzes news articles from Google News. Built with **Playwright** and **BeautifulSoup**, this scraper searches for articles about web scraping, extracts titles and URLs, analyzes content for specific keywords, and exports everything to a structured CSV file.

The tool uses browser automation to handle dynamic content, cookie consent dialogs, and JavaScript-rendered pages, making it robust and reliable for news data extraction.

---

## **ğŸš€ Key Features**

### **âš¡ Core Functionality**

âœ… **Automated Google News Search** â€” Searches Google News with custom queries  
âœ… **Article Title Extraction** â€” Captures article headlines accurately  
âœ… **URL Collection** â€” Extracts and validates article links  
âœ… **Full Article Scraping** â€” Visits each article page and extracts complete content  
âœ… **Keyword Analysis** â€” Searches for specific keywords (e.g., "proxy", "proxies") in articles  
âœ… **CSV Export** â€” Saves all data in organized CSV format  
âœ… **Cookie Consent Handling** â€” Automatically accepts cookie dialogs  
âœ… **Dynamic Content Support** â€” Handles JavaScript-rendered pages with Playwright  
âœ… **Statistical Reporting** â€” Provides summary of keyword matches found  
âœ… **Customizable Search** â€” Easy to modify search queries and keywords

---

## **ğŸ“¸ Application Screenshots**

<p align="center">
  <img src="https://github.com/user-attachments/assets/3f4f9bd8-bdfe-485b-b3d7-b49502e93f84" alt="Scraper Dashboard" width="700" style="border-radius: 12px;"/>
</p>

<p align="center">
  <img src="https://github.com/user-attachments/assets/8e84982a-70e4-478b-a487-41d80a533923" alt="Article Extraction" width="700" style="border-radius: 12px;"/>
</p>

<p align="center">
  <img src="https://github.com/user-attachments/assets/8b29413b-b65e-43af-8db1-e219bbc613bc" alt="Code Implementation" width="700" style="border-radius: 12px;"/>
</p>

---

## **ğŸ”§ Technical Implementation**

### **Technologies Used:**

- **Python 3.x** â€” Core programming language
- **Playwright** â€” Browser automation for dynamic content
- **BeautifulSoup4** â€” HTML parsing and data extraction
- **CSV Module** â€” Structured data export
- **Chromium Browser** â€” Headless/visible browser automation

### **Architecture:**
```
Browser Launch (Playwright)
    â†“
Google News Search
    â†“
HTML Parsing (BeautifulSoup)
    â†“
Article Link Extraction
    â†“
Visit Each Article Page
    â†“
Content Analysis & Keyword Detection
    â†“
CSV Data Export
```

---

## **ğŸ’¡ How It Works**

### **Step-by-Step Process:**

1. **ğŸŒ Launch Browser** â€” Playwright opens Chromium browser (visible mode for debugging)
2. **ğŸ” Search Google News** â€” Navigates to Google News with predefined search query
3. **ğŸª Handle Cookies** â€” Automatically accepts cookie consent if prompted
4. **ğŸ“‹ Extract Links** â€” Parses page HTML to find article titles and URLs
5. **ğŸ“„ Visit Articles** â€” Opens each article link to access full content
6. **ğŸ” Keyword Search** â€” Scans article text for specified keywords (case-insensitive)
7. **ğŸ’¾ Save to CSV** â€” Writes title, URL, and keyword match status to CSV file
8. **ğŸ“Š Generate Report** â€” Displays summary statistics of findings

---

## **ğŸ“Š Output Format**

The scraper generates a CSV file with the following structure:

| Title | URL | Contains Proxy |
|-------|-----|----------------|
| Article headline | Full article URL | True/False |

**Example Output:**
```
Title: "Web Scraping Best Practices in 2024"
URL: https://example.com/article
Contains Proxy: True

5/10 articles contained proxy keywords.
```

---

## **âš™ï¸ Configuration Options**

### **Customizable Parameters:**

- **Search Query** â€” Modify the Google News search term
- **Article Limit** â€” Change number of articles to scrape (default: 10)
- **Keywords** â€” Add or modify keywords to search for
- **CSV Path** â€” Specify output file location
- **Browser Mode** â€” Toggle between headless and visible browser
- **Timeout Settings** â€” Adjust page load wait times

---

## **ğŸ› ï¸ Installation & Setup**

### **Prerequisites:**
```bash
Python 3.7 or higher
pip (Python package manager)
```

### **Installation Steps:**

```bash
# Clone the repository
git clone https://github.com/yourusername/news-scraper.git

# Navigate to project directory
cd news-scraper

# Install required packages
pip install playwright beautifulsoup4

# Install Playwright browsers
playwright install chromium

# Run the scraper
python scraper.py
```

---

## **ğŸ“ Code Structure**

### **Main Components:**

**1. Browser Initialization**
```python
browser = p.chromium.launch(headless=False)
page = browser.new_page()
```

**2. Google News Navigation**
```python
url = "https://news.google.com/search?q=web+scraping"
page.goto(url)
```

**3. Cookie Consent Handling**
```python
accept_button = page.wait_for_selector('text="Accept all"')
page.click('text="Accept all"')
```

**4. Article Extraction**
```python
links = soup.find_all("a", class_="WwrzSb")
titles = soup.find_all("a", class_="JtKRv")
```

**5. Keyword Analysis**
```python
contains_proxy = "proxy" in article_text or "proxies" in article_text
```

**6. CSV Export**
```python
writer.writerow({
    "Title": article_title,
    "URL": page.url,
    "Contains Proxy": contains_proxy
})
```

---

## **ğŸ¯ Use Cases**

âœ”ï¸ **Market Research** â€” Monitor news trends and competitor mentions  
âœ”ï¸ **Content Aggregation** â€” Collect articles on specific topics  
âœ”ï¸ **SEO Analysis** â€” Track keyword usage in news articles  
âœ”ï¸ **Academic Research** â€” Gather news data for studies  
âœ”ï¸ **Media Monitoring** â€” Track coverage of specific subjects  
âœ”ï¸ **Competitive Intelligence** â€” Monitor industry news and developments

---

## **ğŸ”’ Features Breakdown**

### **ğŸ¤– Browser Automation**
- Handles dynamic JavaScript content
- Manages cookie consent dialogs
- Waits for content to load properly
- Supports both headless and visible modes

### **ğŸ“Š Data Processing**
- Extracts structured data from HTML
- Validates and fixes relative URLs
- Case-insensitive keyword matching
- Clean CSV output formatting

### **âš¡ Performance**
- Configurable timeout settings
- Efficient HTML parsing
- Batch processing of articles
- Error handling for robustness

---

## **ğŸš€ Future Enhancements**

ğŸ”¹ Support for multiple news sources  
ğŸ”¹ Advanced keyword analysis (NLP)  
ğŸ”¹ Sentiment analysis integration  
ğŸ”¹ Database storage option  
ğŸ”¹ Scheduled automatic runs  
ğŸ”¹ Email notifications for new articles  
ğŸ”¹ GUI interface for easy configuration  

---

## **ğŸ”— Connect With Me**

**LinkedIn:**  
ğŸ”µ [Shoaib Altaf](https://www.linkedin.com/in/shoaib-altaf-2a1760313/)

**Instagram:**  
ğŸ“· [@shoaib_altaf1965](https://instagram.com/shoaib_altaf1965)

---

## **â­ Support**

If you find this project useful, please **â­ star the repository** â€” it helps support future development!

---

## **ğŸ“„ License**

This project is licensed under the **MIT License**.  
See the [LICENSE](LICENSE) file for details.

---

**ğŸ” Automating News Intelligence | ğŸ Built with Python**
